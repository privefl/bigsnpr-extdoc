# Preprocessing

```{r setup, include=FALSE}
WORDS_TO_IGNORE <- c("XGBoost")
source("knitr-options.R")
source("spelling-check.R")
library(bigsnpr)
```

In this section, I am including conversion, quality control and imputation.

## Conversion and quality control of PLINK files

PLINK is very efficient for conversion and quality control of multiple formats, so I have decided just using it.

In {bigsnpr}, I provide some wrappers to PLINK for ease of use:

- `download_plink()` and `download_plink2()` for downloading the latest stable versions of PLINK 1.9 and 2.0.

- `snp_plinkQC()` for quality control (QC) and conversion to bed/bim/fam.

- `snp_plinkKINGQC()` for QC on relatedness based on KING-robust kinship estimator. Using `make.bed = FALSE` allows for computing related pairs only, i.e. reporting a data frame without producing new bed/bim/fam files.
	
- `snp_plinkIBDQC()` for QC based on identity-by-descent (IBD) computed by PLINK using its method-of-moments.
	
- `snp_plinkRmSamples()` for producing new PLINK files after having removed some individuals.

- For any other PLINK function, I recommend calling PLINK directly from `r icon::fa_r_project()` thanks to system calls and package {glue}, e.g.
    ```{r}
    plink <- download_plink("tmp-data")
    system(glue::glue(
      "{plink} --version"
    ))
    ```


## Imputation

Note that most functions from {bigstatsr} and {bigsnpr} don't handle missing values.

Simple imputation (e.g. by the mean) of a 'double' FBM can be performed by blocks using e.g. as explained in [this vignette](https://privefl.github.io/bigstatsr/articles/big-apply.html).

In {bigsnpr}, to perform simple imputation of genotyped data, you can use `snp_fastImputeSimple()`. You can also use `snp_fastImpute()` that uses XGBoost models to impute genotyped data (slower but still fast enough, described in @prive2017efficient).


## Exercise: preprocessing {#exo-preprocessing}

For the exercises, we will use the data provided in @reed2015guide.

This can be downloaded using 
```{r}
url <- "https://www.mtholyoke.edu/courses/afoulkes/Data/statsTeachR/"
sapply(paste0(url, "GWAS_data", c(".bed", ".bim", ".fam")),
       runonce::download_file, dir = "tmp-data")
```

For some reason, this data is not ordered by chromosome and position; we can use PLINK to get an ordered version of this using
```{r}
library(bigsnpr)
plink <- download_plink("tmp-data")
```

```{r}
system(glue::glue(
  "{plink} --bfile tmp-data/GWAS_data",
  " --make-bed --out tmp-data/GWAS_data_sorted"
))
```

As you can see from PLINK output, this data contains 1401 individuals and 500,000 variants, with a few missing values.

We can then perform some quality control using
```{r, include=FALSE}
file.remove(paste0("tmp-data/GWAS_data_sorted_QC", 
                   c(".bed", ".bim", ".fam", ".bk", ".rds")))
```
```{r}
bedfile2 <- snp_plinkQC(plink, "tmp-data/GWAS_data_sorted")
```
404,663 variants are remaining after this quality control; we can then read this data into an R object called `bigSNP` using
```{r}
(rds <- snp_readBed2(bedfile2, ncores = nb_cores()))
obj.bigsnp <- snp_attach(rds)
str(obj.bigsnp, max.level = 2)
```

Recall that this data contains some missing values; you can get some counts per variant using
```{r}
G <- obj.bigsnp$genotypes
counts <- big_counts(G)
counts[, 1:8]
hist(nbNA <- counts[4, ])
```

We can e.g. perform a quick imputation by the mean using 
```{r}
G2 <- snp_fastImputeSimple(G, method = "mean2", ncores = nb_cores())
big_counts(G2, ind.col = 1:8)
big_counts(G, ind.col = 1:8)
```

`G` still has missing values, but `G2` does not. Note that both are using the same data, the difference is that they using a different code to decode the underlying data:
```{r}
G$code256
G2$code256
```

To always use the new code, you need to save it using
```{r}
obj.bigsnp$genotypes <- G2
snp_save(obj.bigsnp)
```

You can re-attach this data in another R session later using `snp_attach("tmp-data/GWAS_data_sorted_QC.rds")`.  
